# 目标检测算法

根据目标检测原理大致可以先根据**两阶段**和**单阶段**划分，两阶段一般精度较高但计算量较大pipline更复杂所以速度更慢，单阶段模型pipline简单优雅，但精度一般稍逊一筹，随着object detection发展，单阶段模型精度已经慢慢达到甚至超越双阶段的baseline。后期又发展出`anchor-base`和`anchor-free`（主要是单阶段，孤陋寡闻没听说双阶段有anchor-free的）的算法。近期由于`transformer`的跨界，也有很多更强的新模型出现，在cv界大杀四方，靠暴力的参数量疯狂屠榜（半开玩笑，误！），由于工作主要还是对落地有较高要求（主要是性价比），本人暂无详细研究（2019年底我又回归OCR大业，主要搞回文本检测，文本识别，轻量化网络等方面的东西去了，所以后面百花齐放的通用目标检测算法也只有纸上谈兵了），等待后续钻研。

## 两阶段与单阶段大致区别

字面意思，两阶段是将目标检测分为两大部分，简单来说第一阶段是基于分类思想，先把前景和目标分离开，第二阶段再精调目标框。单阶段是一步到位，基本上就是以回归的思想直接把目标检测的活一次干完，两者的算法理念不同，各有优缺点。随着时间发展，两阶段的成本问题以及单阶段的性能不断提升，工业场景基本上都是单阶段目标检测模型落地了（据我所知）。

## 两阶段

发展大致从RCNN -> fast RCNN -> faster RCNN -> Cascade RCNN

### RCNN

* 原理&pipline
* 贡献&亮点
* 源码

### fast-RCNN

* 原理&pipline
* 贡献&亮点
* 源码

### faster-RCNN

* 原理&pipline
* 贡献&亮点
* 源码

### Cascade-RCNN

* 原理&pipline
* 贡献&亮点
* 源码



## 单阶段

发展大致从YOLO v1 -> SSD -> YOLO v2 -> YOLO v3 -> RetinaNet -> FCOS -> CenterNet -> YOLO v4，v5，YOLOF，YOLOR，YOLOX，YOLOE等各种花式YOLO变体（大部分还是叠加工程trick，算法大改进没感觉有啥）以及基于transformer（应该算是单阶段？）等。

### YOLO v1

* 原理&pipline
* 贡献&亮点
* 源码

### YOLO v2

* 原理&pipline
* 贡献&亮点
* 源码

### YOLO v3

* 原理&pipline
* 贡献&亮点
* 源码

### SSD

* 原理&pipline
* 贡献&亮点
* 源码

### RetinaNet

* 原理&pipline
* 贡献&亮点
* 源码

### FCOS

* 原理&pipline
* 贡献&亮点
* 源码

### CenterNet

* 原理&pipline
* 贡献&亮点
* 源码

### YOLO v4

* 原理&pipline
* 贡献&亮点
* 源码

### YOLO v5

* 原理&pipline
* 贡献&亮点
* 源码

### YOLOF

* 原理&pipline
* 贡献&亮点
* 源码

### YOLOR

* 原理&pipline
* 贡献&亮点
* 源码

### YOLOX

* 原理&pipline
* 贡献&亮点
* 源码

### YOLOE

* 原理&pipline
* 贡献&亮点
  * baidu集各种工程trick的集大成之作，可以说是工业上拿来即用的神器了
* 源码



## Transformer
### 待学习待研究。。。
